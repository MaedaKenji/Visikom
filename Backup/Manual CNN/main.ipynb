{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "def load_data(dataset_path='Datasets/numbers/mnist_png/Hnd'):\n",
    "    \"\"\"\n",
    "    Fungsi untuk memuat data dari folder dataset.\n",
    "    Setiap folder (Sample0, Sample1, â€¦, Sample9) mewakili kelas angka.\n",
    "    Citra dibaca dalam mode grayscale, diflatten dan dinormalisasi.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    # Lakukan iterasi untuk setiap kelas digit 0-9\n",
    "    for digit in range(10):\n",
    "        folder = os.path.join(dataset_path, f\"Sample{digit}\")\n",
    "        # Pastikan folder ada\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"Folder {folder} tidak ditemukan.\")\n",
    "            continue\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith('.png'):\n",
    "                filepath = os.path.join(folder, filename)\n",
    "                # Baca gambar dalam grayscale\n",
    "                img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                # Flatten citra menjadi vektor 1D dan normalisasi nilai piksel ke [0,1]\n",
    "                img_flat = img.flatten().astype(np.float32) / 255.0\n",
    "                X.append(img_flat)\n",
    "                y.append(digit)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(f\"img shape {img.shape}\")\n",
    "    print(f\"img flat : {X[0].shape}\")\n",
    "    return X, y\n",
    "\n",
    "def one_hot_encode(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Mengubah label y menjadi format one-hot.\n",
    "    \"\"\"\n",
    "    one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    # print(\"One hot before: \", one_hot)\n",
    "    one_hot[np.arange(y.shape[0]), y] = 1\n",
    "    # print(\"One hot after: \", one_hot)\n",
    "    return one_hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Fungsi softmax untuk mengubah output linear menjadi probabilitas.\n",
    "    Dikurangi nilai maksimum tiap baris untuk kestabilan numerik.\n",
    "    \"\"\"\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    # print(f\"exp_z: {exp_z} np.max: {np.max(z, axis=1, keepdims=True)} np.sum: {np.sum(exp_z, axis=1, keepdims=True)}\") \n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "def save_model(model, filename=\"model_gray.npz\"):\n",
    "    \"\"\"\n",
    "    Menyimpan model ke file NPZ.\n",
    "    Parameter yang disimpan adalah weight (W) dan bias (b).\n",
    "    \"\"\"\n",
    "    np.savez(filename, W=model['W'], b=model['b'])\n",
    "    print(f\"Model disimpan ke file {filename}\")\n",
    "    \n",
    "def load_model(filename=\"model.npz\"):\n",
    "    \"\"\"\n",
    "    Memuat model dari file NPZ.\n",
    "    Mengembalikan dictionary dengan weight (W), bias (b),\n",
    "    dan fungsi net serta netfunction untuk prediksi.\n",
    "    \"\"\"\n",
    "    data = np.load(filename)\n",
    "    W = data['W']\n",
    "    b = data['b']\n",
    "    \n",
    "    def net(x):\n",
    "        return np.dot(x, W) + b\n",
    "\n",
    "    def netfunction(x):\n",
    "        # Pastikan fungsi softmax sudah didefinisikan\n",
    "        return softmax(net(x))\n",
    "    \n",
    "    model = {\n",
    "        'W': W,\n",
    "        'b': b,\n",
    "        'net': net,\n",
    "        'netfunction': netfunction\n",
    "    }\n",
    "    print(f\"Model berhasil dimuat dari file {filename}\")\n",
    "    return model\n",
    "\n",
    "def train_nn(X, y, learning_rate=0.01, epochs=100):\n",
    "    \"\"\"\n",
    "    Fungsi training untuk model klasifikasi:\n",
    "      - Inisialisasi bobot dan bias\n",
    "      - Lakukan forward pass (net = X.W + b) dan hitung softmax (fnet)\n",
    "      - Hitung loss cross-entropy\n",
    "      - Hitung gradien (dz, dw, db) dengan backpropagation\n",
    "      - Update parameter menggunakan gradient descent\n",
    "      \n",
    "    Log training per epoch disimpan ke file CSV dengan kolom:\n",
    "      Epoch, X, Y_Label, W, b, net, fnet, dw, dz, db\n",
    "      \n",
    "    Note: Untuk menghindari log data yang terlalu besar, hanya nilai sample pertama (index 0)\n",
    "    yang dijadikan representasi.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    print(f\"n_samples: {n_samples}, n_features: {n_features}\")\n",
    "    n_classes = 10\n",
    "\n",
    "    # Inisialisasi bobot dan bias\n",
    "    W = np.random.randn(n_features, n_classes) * 0.01\n",
    "    b = np.zeros((1, n_classes))\n",
    "\n",
    "    # Ubah label ke format one-hot\n",
    "    y_encoded = one_hot_encode(y, n_classes)\n",
    "    # print(f\"y_encoded: {y_encoded}\")\n",
    "    # print(f\"y_encoded shape: {y_encoded.shape}\")\n",
    "\n",
    "    # List untuk menyimpan log per epoch\n",
    "    log_data = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        Z = np.dot(X, W) + b       # net input\n",
    "        A = softmax(Z)             # fnet, output probabilitas\n",
    "\n",
    "        # Hitung loss cross-entropy\n",
    "        loss = -np.sum(y_encoded * np.log(A + 1e-8)) / n_samples\n",
    "\n",
    "        # Backpropagation\n",
    "        dZ = A - y_encoded         # error (dz)\n",
    "        dW = np.dot(X.T, dZ) / n_samples   # gradien bobot\n",
    "        db = np.sum(dZ, axis=0, keepdims=True) / n_samples  # gradien bias\n",
    "\n",
    "        # Update parameter\n",
    "        W -= learning_rate * dW\n",
    "        b -= learning_rate * db\n",
    "\n",
    "        # Simpan log untuk epoch ini, ambil nilai sample pertama sebagai contoh\n",
    "        log_data.append({\n",
    "            \"Epoch\": epoch,\n",
    "            \"X\": np.array2string(X[0], precision=2, separator=','),\n",
    "            \"Y_Label\": y[0],\n",
    "            \"W\": np.array2string(W, precision=4, separator=','),\n",
    "            \"b\": np.array2string(b, precision=4, separator=','),\n",
    "            \"net\": np.array2string(Z[0], precision=4, separator=','),\n",
    "            \"fnet\": np.array2string(A[0], precision=4, separator=','),\n",
    "            \"dw\": np.array2string(dW, precision=4, separator=','),\n",
    "            \"dz\": np.array2string(dZ[0], precision=4, separator=','),\n",
    "            \"db\": np.array2string(db, precision=4, separator=',')\n",
    "        })\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    # Simpan log training ke file CSV\n",
    "    # Tambahkan timestamp ke nama file log\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    csv_filename = f\"training_log_detailed_{timestamp}.csv\"\n",
    "\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        fieldnames = [\"Epoch\", \"X\", \"Y_Label\", \"W\", \"b\", \"net\", \"fnet\", \"dw\", \"dz\", \"db\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in log_data:\n",
    "            writer.writerow(row)\n",
    "    print(f\"Detailed log training disimpan ke file {csv_filename}\")\n",
    "\n",
    "    # Definisikan fungsi net dan netfunction untuk keperluan prediksi\n",
    "    def net(x):\n",
    "        return np.dot(x, W) + b\n",
    "\n",
    "    def netfunction(x):\n",
    "        z = net(x)\n",
    "        return softmax(z)\n",
    "\n",
    "    # Kembalikan model\n",
    "    model = {\n",
    "        'W': W,\n",
    "        'b': b,\n",
    "        'net': net,\n",
    "        'netfunction': netfunction\n",
    "    }\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape (28, 28)\n",
      "img flat : (784,)\n",
      "Data berhasil dimuat. Shape X: (60000, 784) , Shape y: (60000,)\n",
      "n_samples: 60000, n_features: 784\n",
      "Epoch 0/100, Loss: 2.3114\n",
      "Epoch 10/100, Loss: 1.5491\n",
      "Epoch 20/100, Loss: 1.1872\n",
      "Epoch 30/100, Loss: 0.9937\n",
      "Epoch 40/100, Loss: 0.8755\n",
      "Epoch 50/100, Loss: 0.7959\n",
      "Epoch 60/100, Loss: 0.7383\n",
      "Epoch 70/100, Loss: 0.6945\n",
      "Epoch 80/100, Loss: 0.6600\n",
      "Epoch 90/100, Loss: 0.6319\n",
      "Detailed log training disimpan ke file training_log_detailed_20250225_184816.csv\n",
      "Model disimpan ke file model.npz\n",
      "Prediksi kelas untuk sample pertama: 0\n",
      "Bias shape:  (1, 10)\n",
      "Weight shape:  (784, 10)\n",
      "Detail prediksi disimpan ke file prediction_details.txt\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Memuat data dari folder dataset\n",
    "    X, y = load_data()\n",
    "    print(\"Data berhasil dimuat. Shape X:\", X.shape, \", Shape y:\", y.shape)\n",
    "\n",
    "    # Training model dengan parameter tertentu (misal: learning_rate=0.1, epochs=100)\n",
    "    model = train_nn(X, y, learning_rate=0.1, epochs=100)\n",
    "\n",
    "    # Contoh prediksi untuk data pertama\n",
    "    sample = X[0].reshape(1, -1)\n",
    "    net_value = model['net'](sample)           # Nilai linear (net)\n",
    "    fnet_value = model['netfunction'](sample)    # Output softmax (fnet)\n",
    "    predicted_class = np.argmax(fnet_value)\n",
    "    save_model(model, \"model_gray.npz\")\n",
    "    print(\"Prediksi kelas untuk sample pertama:\", predicted_class)\n",
    "    print(\"Bias shape: \", model['b'].shape)\n",
    "    print(\"Weight shape: \", model['W'].shape)\n",
    "\n",
    "    # Simpan nilai prediksi (net dan fnet) ke file teks\n",
    "    with open(\"prediction_details.txt\", \"w\") as f:\n",
    "        f.write(\"Prediksi untuk sample pertama:\\n\")\n",
    "        f.write(f\"Predicted Class: {predicted_class}\\n\\n\")\n",
    "        f.write(\"Net (nilai linear):\\n\")\n",
    "        f.write(np.array2string(net_value, precision=4, separator=', ') + \"\\n\\n\")\n",
    "        f.write(\"fnet (hasil softmax):\\n\")\n",
    "        f.write(np.array2string(fnet_value, precision=4, separator=', ') + \"\\n\")\n",
    "        # Write nilai weight dan bias\n",
    "        f.write(\"\\nWeight:\\n\")\n",
    "        f.write(np.array2string(model['W'], precision=4, separator=', ') + \"\\n\\n\")\n",
    "        f.write(\"Bias:\\n\")\n",
    "        f.write(np.array2string(model['b'], precision=4, separator=', ') + \"\\n\")\n",
    "    print(\"Detail prediksi disimpan ke file prediction_details.txt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "def load_data(dataset_path='Datasets/numbers/mnist_png/Hnd'):\n",
    "    \"\"\"\n",
    "    Fungsi untuk memuat data dari folder dataset.\n",
    "    Setiap folder (Sample0, Sample1, â€¦, Sample9) mewakili kelas angka.\n",
    "    Citra dibaca dalam mode grayscale, diflatten dan dinormalisasi.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    # Lakukan iterasi untuk setiap kelas digit 0-9\n",
    "    for digit in range(10):\n",
    "        folder = os.path.join(dataset_path, f\"Sample{digit}\")\n",
    "        # Pastikan folder ada\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"Folder {folder} tidak ditemukan.\")\n",
    "            continue\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith('.png'):\n",
    "                filepath = os.path.join(folder, filename)\n",
    "                # Baca gambar dalam grayscale\n",
    "                img = cv2.imread(filepath)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                # Flatten citra menjadi vektor 1D dan normalisasi nilai piksel ke [0,1]\n",
    "                img_flat = img.flatten().astype(np.float32) / 255.0\n",
    "                X.append(img_flat)\n",
    "                y.append(digit)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(f\"img shape {img.shape}\")\n",
    "    print(f\"img flat : {X[0].shape}\")\n",
    "    return X, y\n",
    "\n",
    "def one_hot_encode(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Mengubah label y menjadi format one-hot.\n",
    "    \"\"\"\n",
    "    one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    # print(\"One hot before: \", one_hot)\n",
    "    one_hot[np.arange(y.shape[0]), y] = 1\n",
    "    # print(\"One hot after: \", one_hot)\n",
    "    return one_hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Fungsi softmax untuk mengubah output linear menjadi probabilitas.\n",
    "    Dikurangi nilai maksimum tiap baris untuk kestabilan numerik.\n",
    "    \"\"\"\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    # print(f\"exp_z: {exp_z} np.max: {np.max(z, axis=1, keepdims=True)} np.sum: {np.sum(exp_z, axis=1, keepdims=True)}\") \n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "def save_model(model, filename=\"model_color.npz\"):\n",
    "    \"\"\"\n",
    "    Menyimpan model ke file NPZ.\n",
    "    Parameter yang disimpan adalah weight (W) dan bias (b).\n",
    "    \"\"\"\n",
    "    np.savez(filename, W=model['W'], b=model['b'])\n",
    "    print(f\"Model disimpan ke file {filename}\")\n",
    "    \n",
    "def load_model(filename=\"model.npz\"):\n",
    "    \"\"\"\n",
    "    Memuat model dari file NPZ.\n",
    "    Mengembalikan dictionary dengan weight (W), bias (b),\n",
    "    dan fungsi net serta netfunction untuk prediksi.\n",
    "    \"\"\"\n",
    "    data = np.load(filename)\n",
    "    W = data['W']\n",
    "    b = data['b']\n",
    "    \n",
    "    def net(x):\n",
    "        return np.dot(x, W) + b\n",
    "\n",
    "    def netfunction(x):\n",
    "        # Pastikan fungsi softmax sudah didefinisikan\n",
    "        return softmax(net(x))\n",
    "    \n",
    "    model = {\n",
    "        'W': W,\n",
    "        'b': b,\n",
    "        'net': net,\n",
    "        'netfunction': netfunction\n",
    "    }\n",
    "    print(f\"Model berhasil dimuat dari file {filename}\")\n",
    "    return model\n",
    "\n",
    "def train_nn(X, y, learning_rate=0.01, epochs=100):\n",
    "    \"\"\"\n",
    "    Fungsi training untuk model klasifikasi:\n",
    "      - Inisialisasi bobot dan bias\n",
    "      - Lakukan forward pass (net = X.W + b) dan hitung softmax (fnet)\n",
    "      - Hitung loss cross-entropy\n",
    "      - Hitung gradien (dz, dw, db) dengan backpropagation\n",
    "      - Update parameter menggunakan gradient descent\n",
    "      \n",
    "    Log training per epoch disimpan ke file CSV dengan kolom:\n",
    "      Epoch, X, Y_Label, W, b, net, fnet, dw, dz, db\n",
    "      \n",
    "    Note: Untuk menghindari log data yang terlalu besar, hanya nilai sample pertama (index 0)\n",
    "    yang dijadikan representasi.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    print(f\"n_samples: {n_samples}, n_features: {n_features}\")\n",
    "    n_classes = 10\n",
    "\n",
    "    # Inisialisasi bobot dan bias\n",
    "    W = np.random.randn(n_features, n_classes) * 0.01\n",
    "    b = np.zeros((1, n_classes))\n",
    "\n",
    "    # Ubah label ke format one-hot\n",
    "    y_encoded = one_hot_encode(y, n_classes)\n",
    "    # print(f\"y_encoded: {y_encoded}\")\n",
    "    # print(f\"y_encoded shape: {y_encoded.shape}\")\n",
    "\n",
    "    # List untuk menyimpan log per epoch\n",
    "    log_data = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        Z = np.dot(X, W) + b       # net input\n",
    "        A = softmax(Z)             # fnet, output probabilitas\n",
    "\n",
    "        # Hitung loss cross-entropy\n",
    "        loss = -np.sum(y_encoded * np.log(A + 1e-8)) / n_samples\n",
    "\n",
    "        # Backpropagation\n",
    "        dZ = A - y_encoded         # error (dz)\n",
    "        dW = np.dot(X.T, dZ) / n_samples   # gradien bobot\n",
    "        db = np.sum(dZ, axis=0, keepdims=True) / n_samples  # gradien bias\n",
    "\n",
    "        # Update parameter\n",
    "        W -= learning_rate * dW\n",
    "        b -= learning_rate * db\n",
    "\n",
    "        # Simpan log untuk epoch ini, ambil nilai sample pertama sebagai contoh\n",
    "        log_data.append({\n",
    "            \"Epoch\": epoch,\n",
    "            \"X\": np.array2string(X[0], precision=2, separator=','),\n",
    "            \"Y_Label\": y[0],\n",
    "            \"W\": np.array2string(W, precision=4, separator=','),\n",
    "            \"b\": np.array2string(b, precision=4, separator=','),\n",
    "            \"net\": np.array2string(Z[0], precision=4, separator=','),\n",
    "            \"fnet\": np.array2string(A[0], precision=4, separator=','),\n",
    "            \"dw\": np.array2string(dW, precision=4, separator=','),\n",
    "            \"dz\": np.array2string(dZ[0], precision=4, separator=','),\n",
    "            \"db\": np.array2string(db, precision=4, separator=',')\n",
    "        })\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    # Simpan log training ke file CSV\n",
    "    # Tambahkan timestamp ke nama file log\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    csv_filename = f\"training_log_detailed_{timestamp}.csv\"\n",
    "\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        fieldnames = [\"Epoch\", \"X\", \"Y_Label\", \"W\", \"b\", \"net\", \"fnet\", \"dw\", \"dz\", \"db\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in log_data:\n",
    "            writer.writerow(row)\n",
    "    print(f\"Detailed log training disimpan ke file {csv_filename}\")\n",
    "\n",
    "    # Definisikan fungsi net dan netfunction untuk keperluan prediksi\n",
    "    def net(x):\n",
    "        return np.dot(x, W) + b\n",
    "\n",
    "    def netfunction(x):\n",
    "        z = net(x)\n",
    "        return softmax(z)\n",
    "\n",
    "    # Kembalikan model\n",
    "    model = {\n",
    "        'W': W,\n",
    "        'b': b,\n",
    "        'net': net,\n",
    "        'netfunction': netfunction\n",
    "    }\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape (28, 28, 3)\n",
      "img flat : (2352,)\n",
      "Data berhasil dimuat. Shape X: (60000, 2352) , Shape y: (60000,)\n",
      "n_samples: 60000, n_features: 2352\n",
      "Epoch 0/100, Loss: 2.3114\n",
      "Epoch 10/100, Loss: 0.9870\n",
      "Epoch 20/100, Loss: 0.7357\n",
      "Epoch 30/100, Loss: 0.6310\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetail prediksi disimpan ke file prediction_details.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData berhasil dimuat. Shape X:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, Shape y:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Training model dengan parameter tertentu (misal: learning_rate=0.1, epochs=100)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Contoh prediksi untuk data pertama\u001b[39;00m\n\u001b[0;32m     10\u001b[0m sample \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 78\u001b[0m, in \u001b[0;36mtrain_nn\u001b[1;34m(X, y, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     Z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X, W) \u001b[38;5;241m+\u001b[39m b       \u001b[38;5;66;03m# net input\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m             \u001b[38;5;66;03m# fnet, output probabilitas\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Hitung loss cross-entropy\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(y_encoded \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(A \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)) \u001b[38;5;241m/\u001b[39m n_samples\n",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(z)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msoftmax\u001b[39m(z):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Fungsi softmax untuk mengubah output linear menjadi probabilitas.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Dikurangi nilai maksimum tiap baris untuk kestabilan numerik.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     exp_z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(z \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(z, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Memuat data dari folder dataset\n",
    "    X, y = load_data()\n",
    "    print(\"Data berhasil dimuat. Shape X:\", X.shape, \", Shape y:\", y.shape)\n",
    "\n",
    "    # Training model dengan parameter tertentu (misal: learning_rate=0.1, epochs=100)\n",
    "    model = train_nn(X, y, learning_rate=0.1, epochs=100)\n",
    "\n",
    "    # Contoh prediksi untuk data pertama\n",
    "    sample = X[0].reshape(1, -1)\n",
    "    net_value = model['net'](sample)           # Nilai linear (net)\n",
    "    fnet_value = model['netfunction'](sample)    # Output softmax (fnet)\n",
    "    predicted_class = np.argmax(fnet_value)\n",
    "    save_model(model, \"model.npz\")\n",
    "    print(\"Prediksi kelas untuk sample pertama:\", predicted_class)\n",
    "    print(\"Bias shape: \", model['b'].shape)\n",
    "    print(\"Weight shape: \", model['W'].shape)\n",
    "\n",
    "    # Simpan nilai prediksi (net dan fnet) ke file teks\n",
    "    with open(\"prediction_details.txt\", \"w\") as f:\n",
    "        f.write(\"Prediksi untuk sample pertama:\\n\")\n",
    "        f.write(f\"Predicted Class: {predicted_class}\\n\\n\")\n",
    "        f.write(\"Net (nilai linear):\\n\")\n",
    "        f.write(np.array2string(net_value, precision=4, separator=', ') + \"\\n\\n\")\n",
    "        f.write(\"fnet (hasil softmax):\\n\")\n",
    "        f.write(np.array2string(fnet_value, precision=4, separator=', ') + \"\\n\")\n",
    "        # Write nilai weight dan bias\n",
    "        f.write(\"\\nWeight:\\n\")\n",
    "        f.write(np.array2string(model['W'], precision=4, separator=', ') + \"\\n\\n\")\n",
    "        f.write(\"Bias:\\n\")\n",
    "        f.write(np.array2string(model['b'], precision=4, separator=', ') + \"\\n\")\n",
    "    print(\"Detail prediksi disimpan ke file prediction_details.txt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 100 x 100 Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(dataset_path='Datasets/SizeSeratus/numbers/mnist_png'):\n",
    "    X = []\n",
    "    y = []\n",
    "    # Lakukan iterasi untuk setiap kelas digit 0-9\n",
    "    for digit in range(10):\n",
    "        folder = os.path.join(dataset_path, f\"Sample{digit}\")\n",
    "        # Pastikan folder ada\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"Folder {folder} tidak ditemukan.\")\n",
    "            continue\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith('.png'):\n",
    "                filepath = os.path.join(folder, filename)\n",
    "                # Baca gambar dalam grayscale\n",
    "                img = cv2.imread(filepath)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                # Flatten citra menjadi vektor 1D dan normalisasi nilai piksel ke [0,1]\n",
    "                img_flat = img.flatten().astype(np.float32) / 255.0\n",
    "                X.append(img_flat)\n",
    "                y.append(digit)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(f\"img shape {img.shape}\")\n",
    "    print(f\"img flat : {X[0].shape}\")\n",
    "    return X, y\n",
    "\n",
    "def one_hot_encode(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Mengubah label y menjadi format one-hot.\n",
    "    \"\"\"\n",
    "    one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    # print(\"One hot before: \", one_hot)\n",
    "    one_hot[np.arange(y.shape[0]), y] = 1\n",
    "    # print(\"One hot after: \", one_hot)\n",
    "    y = np.array(y)\n",
    "    # Dataframe y dan y encoded comparison\n",
    "    df = pd.DataFrame(data=y, columns=['y'])\n",
    "    df2 = pd.DataFrame(data=one_hot, columns=['y0', 'y1', 'y2', 'y3', 'y4', 'y5', 'y6', 'y7', 'y8', 'y9'])\n",
    "    df = pd.concat([df, df2], axis=1)\n",
    "    print(df)\n",
    "    return one_hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Fungsi softmax untuk mengubah output linear menjadi probabilitas.\n",
    "    Dikurangi nilai maksimum tiap baris untuk kestabilan numerik.\n",
    "    \"\"\"\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    # print(f\"exp_z: {exp_z} np.max: {np.max(z, axis=1, keepdims=True)} np.sum: {np.sum(exp_z, axis=1, keepdims=True)}\") \n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "def save_model(model, filename=\"model_color.npz\"):\n",
    "    \"\"\"\n",
    "    Menyimpan model ke file NPZ.\n",
    "    Parameter yang disimpan adalah weight (W) dan bias (b).\n",
    "    \"\"\"\n",
    "    np.savez(filename, W=model['W'], b=model['b'])\n",
    "    print(f\"Model disimpan ke file {filename}\")\n",
    "    \n",
    "def load_model(filename=\"model.npz\"):\n",
    "    \"\"\"\n",
    "    Memuat model dari file NPZ.\n",
    "    Mengembalikan dictionary dengan weight (W), bias (b),\n",
    "    dan fungsi net serta netfunction untuk prediksi.\n",
    "    \"\"\"\n",
    "    data = np.load(filename)\n",
    "    W = data['W']\n",
    "    b = data['b']\n",
    "    \n",
    "    def net(x):\n",
    "        return np.dot(x, W) + b\n",
    "\n",
    "    def netfunction(x):\n",
    "        # Pastikan fungsi softmax sudah didefinisikan\n",
    "        return softmax(net(x))\n",
    "    \n",
    "    model = {\n",
    "        'W': W,\n",
    "        'b': b,\n",
    "        'net': net,\n",
    "        'netfunction': netfunction\n",
    "    }\n",
    "    print(f\"Model berhasil dimuat dari file {filename}\")\n",
    "    return model\n",
    "\n",
    "def train_nn(X, y, learning_rate=0.01, epochs=100):\n",
    "    \"\"\"\n",
    "    Fungsi training untuk model klasifikasi:\n",
    "      - Inisialisasi bobot dan bias\n",
    "      - Lakukan forward pass (net = X.W + b) dan hitung softmax (fnet)\n",
    "      - Hitung loss cross-entropy\n",
    "      - Hitung gradien (dz, dw, db) dengan backpropagation\n",
    "      - Update parameter menggunakan gradient descent\n",
    "      \n",
    "    Log training per epoch disimpan ke file CSV dengan kolom:\n",
    "      Epoch, X, Y_Label, W, b, net, fnet, dw, dz, db\n",
    "      \n",
    "    Note: Untuk menghindari log data yang terlalu besar, hanya nilai sample pertama (index 0)\n",
    "    yang dijadikan representasi.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    print(f\"n_samples: {n_samples}, n_features: {n_features}\")\n",
    "    n_classes = 10\n",
    "\n",
    "    # Inisialisasi bobot dan bias\n",
    "    W = np.random.randn(n_features, n_classes) * 0.01\n",
    "    b = np.zeros((1, n_classes))\n",
    "\n",
    "    # Ubah label ke format one-hot\n",
    "    y_encoded = one_hot_encode(y, n_classes)\n",
    "    # print(f\"y_encoded: {y_encoded}\")\n",
    "    # print(f\"y_encoded shape: {y_encoded.shape}\")\n",
    "\n",
    "    # List untuk menyimpan log per epoch\n",
    "    log_data = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        Z = np.dot(X, W) + b       # net input\n",
    "        A = softmax(Z)             # fnet, output probabilitas\n",
    "\n",
    "        # Hitung loss cross-entropy\n",
    "        loss = -np.sum(y_encoded * np.log(A + 1e-8)) / n_samples\n",
    "\n",
    "        # Backpropagation\n",
    "        dZ = A - y_encoded         # error (dz)\n",
    "        dW = np.dot(X.T, dZ) / n_samples   # gradien bobot\n",
    "        db = np.sum(dZ, axis=0, keepdims=True) / n_samples  # gradien bias\n",
    "\n",
    "        # Update parameter\n",
    "        W -= learning_rate * dW\n",
    "        b -= learning_rate * db\n",
    "\n",
    "        # Simpan log untuk epoch ini, ambil nilai sample pertama sebagai contoh\n",
    "        log_data.append({\n",
    "            \"Epoch\": epoch,\n",
    "            \"X\": np.array2string(X[0], precision=2, separator=','),\n",
    "            \"Y_Label\": y[0],\n",
    "            \"W\": np.array2string(W, precision=4, separator=','),\n",
    "            \"b\": np.array2string(b, precision=4, separator=','),\n",
    "            \"net\": np.array2string(Z[0], precision=4, separator=','),\n",
    "            \"fnet\": np.array2string(A[0], precision=4, separator=','),\n",
    "            \"dw\": np.array2string(dW, precision=4, separator=','),\n",
    "            \"dz\": np.array2string(dZ[0], precision=4, separator=','),\n",
    "            \"db\": np.array2string(db, precision=4, separator=',')\n",
    "        })\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    # Simpan log training ke file CSV\n",
    "    # Tambahkan timestamp ke nama file log\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    csv_filename = f\"training_log_detailed_{timestamp}.csv\"\n",
    "\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        fieldnames = [\"Epoch\", \"X\", \"Y_Label\", \"W\", \"b\", \"net\", \"fnet\", \"dw\", \"dz\", \"db\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in log_data:\n",
    "            writer.writerow(row)\n",
    "    print(f\"Detailed log training disimpan ke file {csv_filename}\")\n",
    "\n",
    "    # Definisikan fungsi net dan netfunction untuk keperluan prediksi\n",
    "    def net(x):\n",
    "        return np.dot(x, W) + b\n",
    "\n",
    "    def netfunction(x):\n",
    "        z = net(x)\n",
    "        return softmax(z)\n",
    "\n",
    "    # Kembalikan model\n",
    "    model = {\n",
    "        'W': W,\n",
    "        'b': b,\n",
    "        'net': net,\n",
    "        'netfunction': netfunction\n",
    "    }\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape (100, 100, 3)\n",
      "img flat : (30000,)\n",
      "Data berhasil dimuat. Shape X: (1097, 30000) , Shape y: (1097,)\n",
      "n_samples: 1097, n_features: 30000\n",
      "      y   y0   y1   y2   y3   y4   y5   y6   y7   y8   y9\n",
      "0     0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "1     0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2     0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "3     0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "4     0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "...  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
      "1092  9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
      "1093  9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
      "1094  9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
      "1095  9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
      "1096  9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
      "\n",
      "[1097 rows x 11 columns]\n",
      "Epoch 0/100, Loss: 2.4784\n",
      "Epoch 10/100, Loss: 4.5220\n",
      "Epoch 20/100, Loss: 0.3806\n",
      "Epoch 30/100, Loss: 0.2033\n",
      "Epoch 40/100, Loss: 0.1384\n",
      "Epoch 50/100, Loss: 0.1019\n",
      "Epoch 60/100, Loss: 0.1248\n",
      "Epoch 70/100, Loss: 0.0879\n",
      "Epoch 80/100, Loss: 0.0573\n",
      "Epoch 90/100, Loss: 0.0464\n",
      "Detailed log training disimpan ke file training_log_detailed_20250228_100212.csv\n"
     ]
    }
   ],
   "source": [
    "# Memuat data dari folder dataset\n",
    "X, y = load_data()\n",
    "print(\"Data berhasil dimuat. Shape X:\", X.shape, \", Shape y:\", y.shape)\n",
    "\n",
    "# Training model dengan parameter tertentu (misal: learning_rate=0.1, epochs=100)\n",
    "model = train_nn(X, y, learning_rate=0.1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi prediksi: 99.70%\n",
      "     Predicted Class  Actual Class  Error\n",
      "0                  0             0  False\n",
      "1                  0             0  False\n",
      "2                  0             0  False\n",
      "3                  0             0  False\n",
      "4                  0             0  False\n",
      "..               ...           ...    ...\n",
      "995                9             9  False\n",
      "996                9             9  False\n",
      "997                9             9  False\n",
      "998                9             9  False\n",
      "999                9             9  False\n",
      "\n",
      "[1000 rows x 3 columns]\n",
      "CSV file telah disimpan dengan nama: prediction_comparison_20250228_100212.csv\n",
      "Input shape:  (1097, 30000)\n",
      "Image shape:  (30000,)\n",
      "Model disimpan ke file model_seratus.npz\n",
      "Bias shape:  (1, 10)\n",
      "Weight shape:  (30000, 10)\n",
      "Detail prediksi disimpan ke file prediction_details.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "predicted_classes = []\n",
    "actual_classes = []\n",
    "\n",
    "# Lakukan prediksi untuk 1000 data pertama\n",
    "for i in range(1000):\n",
    "    sample = X[i].reshape(1, -1)\n",
    "    # Hitung nilai linear (net) dan output softmax (fnet)\n",
    "    net_value = model['net'](sample)\n",
    "    fnet_value = model['netfunction'](sample)\n",
    "    # Prediksi kelas: indeks dengan nilai tertinggi\n",
    "    predicted_class = np.argmax(fnet_value)\n",
    "    \n",
    "    predicted_classes.append(predicted_class)\n",
    "    # Asumsikan y merupakan label aktual untuk data X\n",
    "    actual_classes.append(y[i])\n",
    "\n",
    "# Membuat DataFrame untuk menampilkan tabel perbandingan\n",
    "df = pd.DataFrame({\n",
    "    'Predicted Class': predicted_classes,\n",
    "    'Actual Class': actual_classes\n",
    "})\n",
    "\n",
    "# Menambahkan kolom Error: bernilai True jika prediksi salah, dan False jika benar\n",
    "df['Error'] = df['Predicted Class'] != df['Actual Class']\n",
    "\n",
    "# Atau jika ingin menampilkan sebagai teks \"Correct\" dan \"Incorrect\"\n",
    "# df['Error'] = df.apply(lambda row: 'Incorrect' if row['Predicted Class'] != row['Actual Class'] else 'Correct', axis=1)\n",
    "\n",
    "# Menghitung akurasi prediksi dalam persentase\n",
    "accuracy = (df['Predicted Class'] == df['Actual Class']).mean() * 100\n",
    "print(f\"Akurasi prediksi: {accuracy:.2f}%\")\n",
    "\n",
    "# Menampilkan DataFrame\n",
    "print(df)\n",
    "\n",
    "# Menyimpan tabel ke file CSV dengan timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_filename = f\"prediction_comparison_{timestamp}.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"CSV file telah disimpan dengan nama: {csv_filename}\")\n",
    "\n",
    "# Print input shape\n",
    "print(\"Input shape: \", X.shape)\n",
    "print(\"Image shape: \", X[0].shape)\n",
    "\n",
    "save_model(model, \"model_seratus.npz\")\n",
    "print(\"Bias shape: \", model['b'].shape)\n",
    "print(\"Weight shape: \", model['W'].shape)\n",
    "\n",
    "# Simpan nilai prediksi (net dan fnet) ke file teks\n",
    "with open(\"prediction_details.txt\", \"w\") as f:\n",
    "    f.write(\"Net (nilai linear):\\n\")\n",
    "    f.write(np.array2string(net_value, precision=4, separator=', ') + \"\\n\\n\")\n",
    "    f.write(\"fnet (hasil softmax):\\n\")\n",
    "    f.write(np.array2string(fnet_value, precision=4, separator=', ') + \"\\n\")\n",
    "    # Write nilai weight dan bias\n",
    "    f.write(\"\\nWeight:\\n\")\n",
    "    f.write(np.array2string(model['W'], precision=4, separator=', ') + \"\\n\\n\")\n",
    "    f.write(\"Bias:\\n\")\n",
    "    f.write(np.array2string(model['b'], precision=4, separator=', ') + \"\\n\")\n",
    "print(\"Detail prediksi disimpan ke file prediction_details.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "\n",
    "# Read the image file\n",
    "img = cv2.imread('Datasets/Sample0/1.png')\n",
    "\n",
    "# Print the data matrix\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasets/Sample0/1.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# img = cv2.imread('coba.png', cv2.IMREAD_GRAYSCALE)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# img = cv2.imread('coba.png')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# print 5 rows of the image\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage shape : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m, img)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "img = cv2.imread('Datasets/Sample0/1.png')\n",
    "# img = cv2.imread('coba.png', cv2.IMREAD_GRAYSCALE)\n",
    "# img = cv2.imread('coba.png')\n",
    "\n",
    "# print 5 rows of the image\n",
    "print(img[:5])\n",
    "print(f\"image shape : {img.shape} \")\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# --- Membaca dan menampilkan image dari Datasets/Sample0/1.png ---\n",
    "img0 = cv2.imread('Datasets/Sample0/1.png')\n",
    "if img0 is None:\n",
    "    print(\"Image tidak ditemukan: Datasets/Sample0/1.png\")\n",
    "else:\n",
    "    print(\"Image dari Datasets/Sample0/1.png:\")\n",
    "    print(img0)\n",
    "    print(\"5 baris pertama dari image:\")\n",
    "    print(img0[:5])\n",
    "    print(f\"Shape image: {img0.shape}\")\n",
    "    cv2.imshow('Image Sample0', img0)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# --- Membaca dan menampilkan image dari Datasets/Sample1/1.png ---\n",
    "img1 = cv2.imread('Datasets/Sample1/1.png')\n",
    "if img1 is None:\n",
    "    print(\"Image tidak ditemukan: Datasets/Sample1/1.png\")\n",
    "else:\n",
    "    print(\"Image dari Datasets/Sample1/1.png:\")\n",
    "    print(img1)\n",
    "    print(\"5 baris pertama dari image:\")\n",
    "    print(img1[:5])\n",
    "    print(f\"Shape image: {img1.shape}\")\n",
    "    cv2.imshow('Image Sample1', img1)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# --- Contoh nilai Net dan fnet untuk prediksi ---\n",
    "Net = np.array([[ 5.9158, -3.0557, -1.3257,  0.3136, -2.8025,  1.6988,  0.7880, -0.6799,  0.1001, -0.5342]])\n",
    "\n",
    "\n",
    "# Melakukan prediksi dengan mencari indeks nilai maksimum di fnet\n",
    "prediction = np.argmax(fnet, axis=1)\n",
    "print(f\"Predicted class: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model berhasil dimuat dari file model.npz\n",
      "Image shape: (28, 28, 3)\n",
      "img : [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1254902\n",
      " 0.42745098 0.18431373 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1254902  0.8117647  0.9882353  0.5803922\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.83137256 0.9882353  0.9882353  0.9882353  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00392157 0.32941177 0.99215686 0.9882353\n",
      " 0.9882353  0.65882355 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.24705882 0.24313726 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.3882353  0.9882353  0.99215686 0.9882353  0.6        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1254902  0.92941177\n",
      " 0.92941177 0.28235295 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.70980394 0.9882353\n",
      " 0.99215686 0.7411765  0.03921569 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.54901963 0.9882353  0.9882353  0.61960787\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.20784314 0.9098039  0.9882353  0.99215686 0.29803923\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.70980394 0.9882353  0.9882353  0.13725491 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.28627452\n",
      " 0.9882353  0.9882353  0.7490196  0.05882353 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.5294118  0.99215686 0.99215686\n",
      " 0.80784315 0.07843138 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.85490197 0.99215686 0.99215686\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.36862746 0.96862745 0.9882353  0.9882353  0.68235296 0.28627452\n",
      " 0.28627452 0.28627452 0.16470589 0.         0.         0.\n",
      " 0.36862746 0.96862745 0.9882353  0.9882353  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.5058824  0.9882353\n",
      " 0.9882353  0.9882353  0.9882353  0.9882353  0.9882353  0.9882353\n",
      " 0.87058824 0.70980394 0.70980394 0.70980394 0.83137256 0.9882353\n",
      " 0.9882353  0.90588236 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.6666667  0.9882353  0.9882353  0.9882353\n",
      " 0.9882353  0.9882353  0.9882353  0.9882353  0.99215686 0.9882353\n",
      " 0.9882353  0.9882353  0.99215686 0.9882353  0.9882353  0.42352942\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.43137255 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.7490196  0.5686275  0.5647059  0.627451   0.99215686\n",
      " 1.         0.99215686 0.6039216  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.05882353 0.13725491\n",
      " 0.13725491 0.13725491 0.13725491 0.13725491 0.13725491 0.05882353\n",
      " 0.         0.         0.14509805 0.9882353  0.99215686 0.9882353\n",
      " 0.2784314  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.14509805 0.9882353  0.99215686 0.78431374 0.07843138 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.14509805 0.9882353\n",
      " 0.99215686 0.7019608  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.7137255  0.99215686 1.         0.13725491\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.70980394 0.9882353  0.99215686 0.13725491 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.70980394 0.9882353\n",
      " 0.6862745  0.03921569 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.30588236 0.42352942 0.24313726 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "img setelah diubah: (784,)\n",
      "Predicted class: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_model(filename=\"model.npz\"):\n",
    "    \"\"\"\n",
    "    Memuat model dari file NPZ.\n",
    "    Mengembalikan dictionary dengan weight (W), bias (b),\n",
    "    dan fungsi net serta netfunction untuk prediksi.\n",
    "    \"\"\"\n",
    "    data = np.load(filename)\n",
    "    W = data['W']\n",
    "    b = data['b']\n",
    "    \n",
    "    def net(x):\n",
    "        return np.dot(x, W) + b\n",
    "\n",
    "    def netfunction(x):\n",
    "        # Pastikan fungsi softmax sudah didefinisikan\n",
    "        return softmax(net(x))\n",
    "    \n",
    "    model = {\n",
    "        'W': W,\n",
    "        'b': b,\n",
    "        'net': net,\n",
    "        'netfunction': netfunction\n",
    "    }\n",
    "    print(f\"Model berhasil dimuat dari file {filename}\")\n",
    "    return model\n",
    "\n",
    "model = load_model(\"model.npz\")\n",
    "\n",
    "# Get the first indexed file with .png format in the directory\n",
    "directory = 'Datasets/Sample4'\n",
    "files = [f for f in os.listdir(directory) if f.endswith('.png')]\n",
    "files.sort()  # Ensure the files are sorted\n",
    "if files:\n",
    "    img_path = os.path.join(directory, files[0])\n",
    "    img = cv2.imread(img_path)\n",
    "else:\n",
    "    img = None\n",
    "if img is None:\n",
    "    print(\"Image tidak ditemukan: Datasets/Sample0/1.png\")\n",
    "else:\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    # Resize image menjadi 28x28\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    # Ubah ke grayscale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Ubah ke format float32\n",
    "    img = img.astype(np.float32)\n",
    "    # Normalisasi nilai pixel menjadi 0-1\n",
    "    img = img / 255.0\n",
    "    # Flatten image menjadi vektor\n",
    "    img = img.flatten()\n",
    "    print(f\"img : {img}\")\n",
    "    print(f\"img setelah diubah: {img.shape}\")\n",
    "    # Melakukan prediksi dengan model\n",
    "    fnet = model['net'](img)\n",
    "    prediction = np.argmax(fnet)\n",
    "    print(f\"Predicted class: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
